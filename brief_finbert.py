# -*- coding: utf-8 -*-
"""brief_finbert.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x2lK82tif1MOwynRlXucMA8KA83w4vdW
"""

!pip install transformers

"""# BertForSequenceClassification"""

pip install huggingface_hub

!huggingface-cli login

"""# finbert-tone-finetuned-finance-topic-classification"""

from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F

# 모델 경로
MODEL_NAME = "nickmuchi/finbert-tone-finetuned-finance-topic-classification"

# 토크나이저 & 모델 로딩
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)

# 테스트 문장
texts = [
    "hanseong makes amazing work in electronic car market",
    "Apple's new iPhone failed to impress investors.",
    "The Fed raised interest rates by 0.25 points.",
]

# 라벨 추출
id2label = model.config.id2label  # 예: {0: 'Corporate/Industrial', 1: 'Equity Index', ...}

# 문장 분석
for text in texts:
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = F.softmax(outputs.logits, dim=1)

    top_idx = probs.argmax().item()
    predicted_label = id2label[top_idx]
    confidence = probs[0][top_idx].item()

    print(f"\n📄 텍스트: {text}")
    print(f"→ 예측 주제: {predicted_label} ({confidence * 100:.2f}%)")

    if confidence > 0.7:
        print("✅ 금융 관련 문장으로 간주")
    else:
        print("❌ 금융 관련성 낮음")

"""📄 텍스트: hanseong makes amazing work in electronic car market

→ 예측 주제: Company | Product News (97.16%)

✅ 금융 관련 문장으로 간주

이런 결과를 보니 가짜 뉴스에 대한 대책도 마련 필요
"""

import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F

# 모델 경로
MODEL_NAME = "nickmuchi/finbert-tone-finetuned-finance-topic-classification"

# 모델 불러오기
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)

# CSV 파일 로드
df = pd.read_excel("/content/트위터_수집_(Web)_20250507112834.xlsx")

# 라벨 정보
id2label = model.config.id2label

# 결과 저장 리스트
filtered_results = []

# content 컬럼의 문장 분석
for text in df["본문"].astype(str):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = F.softmax(outputs.logits, dim=1)

    top_idx = probs.argmax().item()
    predicted_label = id2label[top_idx]
    confidence = probs[0][top_idx].item()

    if confidence > 0.7:
        filtered_results.append({
            "text": text,
            "predicted_topic": predicted_label,
            "confidence": round(confidence * 100, 2)
        })

# 결과 DataFrame으로 변환 및 저장
filtered_df = pd.DataFrame(filtered_results)
filtered_df
# filtered_df.to_excel("finance_related_texts.xlsx", index=False)

"""# Main code"""

import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification
import torch
import torch.nn.functional as F
import math

# 1. 금융 관련 주제 분류 모델 (nickmuchi)
TOPIC_MODEL = "nickmuchi/finbert-tone-finetuned-finance-topic-classification"
topic_tokenizer = AutoTokenizer.from_pretrained(TOPIC_MODEL)
topic_model = AutoModelForSequenceClassification.from_pretrained(TOPIC_MODEL)
topic_id2label = topic_model.config.id2label

# 2. 감성 분석 모델 (ProsusAI/finbert)
SENTIMENT_MODEL = "ProsusAI/finbert"
sentiment_tokenizer = BertTokenizer.from_pretrained(SENTIMENT_MODEL)
sentiment_model = BertForSequenceClassification.from_pretrained(SENTIMENT_MODEL)
sentiment_labels = ["positive", "negative", "neutral"]

# 3. 데이터 불러오기
df = pd.read_excel("/content/Filtered_Tweets.csv")
#만약에 크롤링 데이터가 csv파일이면 pd.read.csv()형식으로

# 4. 결과 저장 리스트
results = []

# 5. 문장별 처리
for text in df["fullText"].astype(str):
    # Step 1: 금융 관련 문장 필터링
    inputs_topic = topic_tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs_topic = topic_model(**inputs_topic)
        probs_topic = F.softmax(outputs_topic.logits, dim=1)

    top_idx = probs_topic.argmax().item()
    predicted_topic = topic_id2label[top_idx]
    topic_confidence = probs_topic[0][top_idx].item()

    # 금융 관련도 기준으로 필터링
    if topic_confidence > 0.7:
        # Step 2: 감성 분석
        inputs_sentiment = sentiment_tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
        with torch.no_grad():
            outputs_sentiment = sentiment_model(**inputs_sentiment)
            probs_sentiment = F.softmax(outputs_sentiment.logits, dim=1)

        pos_prob = probs_sentiment[0][sentiment_labels.index("positive")].item()
        neg_prob = probs_sentiment[0][sentiment_labels.index("negative")].item()
        sentiment_score = pos_prob - neg_prob
        predicted_sentiment = sentiment_labels[probs_sentiment.argmax().item()]
        sentiment_confidence = probs_sentiment.max().item()

        # 결과 저장
        results.append({
            "text": text,
            "predicted_topic": predicted_topic,
            "topic_confidence": round(topic_confidence * 100, 2),
            "predicted_sentiment": predicted_sentiment,
            "sentiment_score": round(sentiment_score, 4),
            "sentiment_confidence": round(sentiment_confidence * 100, 2)
        })

# 6. 결과 DataFrame 변환
filtered_df = pd.DataFrame(results)

# sigmoid 보정을 통한 가중 감성 점수 계산
def sigmoid_adjust(conf):
    return 1 / (1 + math.exp(-10 * (conf - 0.5)))  # conf: 0~1로 정규화된 확신도

# 새로운 컬럼 추가
filtered_df["sentiment_confidence_normalized"] = filtered_df["sentiment_confidence"] / 100  # 0~1 범위로 변환
filtered_df["weighted_sentiment_score"] = filtered_df.apply(
    lambda row: row["sentiment_score"] * sigmoid_adjust(row["sentiment_confidence_normalized"]),
    axis=1
)

# 8. 결과 확인
filtered_df.head()
# 7. 저장 (필요 시 주석 해제)
filtered_df.to_excel("finance_sentiment_palantir.xlsx", index=False)

"""# 날짜 포함 감성 분석
대신 트윗이 담겨있는 index와 날짜 index의 형식을 맞춰줘야함


"""

import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification
import torch
import torch.nn.functional as F
import math

# 1. 금융 관련 주제 분류 모델 (nickmuchi)
TOPIC_MODEL = "nickmuchi/finbert-tone-finetuned-finance-topic-classification"
topic_tokenizer = AutoTokenizer.from_pretrained(TOPIC_MODEL)
topic_model = AutoModelForSequenceClassification.from_pretrained(TOPIC_MODEL)
topic_id2label = topic_model.config.id2label

# 2. 감성 분석 모델 (ProsusAI/finbert)
SENTIMENT_MODEL = "ProsusAI/finbert"
sentiment_tokenizer = BertTokenizer.from_pretrained(SENTIMENT_MODEL)
sentiment_model = BertForSequenceClassification.from_pretrained(SENTIMENT_MODEL)
sentiment_labels = ["positive", "negative", "neutral"]

# 3. 데이터 불러오기
df = pd.read_csv("/content/Filtered_Tweets.csv")

# 4. 결과 저장 리스트
results = []

# 5. 문장별 처리
for text, date in zip(df["fullText"].astype(str), df["createdAt"]): # 트윗이 담겨있는 항목으로 바꾸기
    # Step 1: 금융 관련 문장 필터링
    inputs_topic = topic_tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs_topic = topic_model(**inputs_topic)
        probs_topic = F.softmax(outputs_topic.logits, dim=1)

    top_idx = probs_topic.argmax().item()
    predicted_topic = topic_id2label[top_idx]
    topic_confidence = probs_topic[0][top_idx].item()

    if topic_confidence > 0.7:
        # Step 2: 감성 분석
        inputs_sentiment = sentiment_tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
        with torch.no_grad():
            outputs_sentiment = sentiment_model(**inputs_sentiment)
            probs_sentiment = F.softmax(outputs_sentiment.logits, dim=1)

        pos_prob = probs_sentiment[0][sentiment_labels.index("positive")].item()
        neg_prob = probs_sentiment[0][sentiment_labels.index("negative")].item()
        sentiment_score = pos_prob - neg_prob
        predicted_sentiment = sentiment_labels[probs_sentiment.argmax().item()]
        sentiment_confidence = probs_sentiment.max().item()

        results.append({
            "date": date,
            "text": text,
            "predicted_topic": predicted_topic,
            "topic_confidence": round(topic_confidence * 100, 2),
            "predicted_sentiment": predicted_sentiment,
            "sentiment_score": round(sentiment_score, 4),
            "sentiment_confidence": round(sentiment_confidence * 100, 2)
        })

# 6. 결과 DataFrame 변환
filtered_df = pd.DataFrame(results)

# 7. sigmoid 보정된 감정 점수 추가
def sigmoid_adjust(conf):
    return 1 / (1 + math.exp(-10 * (conf - 0.5)))

filtered_df["sentiment_confidence_normalized"] = filtered_df["sentiment_confidence"] / 100
filtered_df["weighted_sentiment_score"] = filtered_df.apply(
    lambda row: row["sentiment_score"] * sigmoid_adjust(row["sentiment_confidence_normalized"]),
    axis=1
)

# 8. Date를 인덱스로 지정하여 저장
filtered_df.set_index("date", inplace=True)
filtered_df.to_excel("sentiment_cleandata.xlsx")

# 9. 미리보기
filtered_df.head()