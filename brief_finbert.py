# -*- coding: utf-8 -*-
"""brief_finbert.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x2lK82tif1MOwynRlXucMA8KA83w4vdW
"""

!pip install transformers

"""# BertForSequenceClassification"""

pip install huggingface_hub

!huggingface-cli login

"""# finbert-tone-finetuned-finance-topic-classification"""

from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F

# ëª¨ë¸ ê²½ë¡œ
MODEL_NAME = "nickmuchi/finbert-tone-finetuned-finance-topic-classification"

# í† í¬ë‚˜ì´ì € & ëª¨ë¸ ë¡œë”©
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)

# í…ŒìŠ¤íŠ¸ ë¬¸ì¥
texts = [
    "hanseong makes amazing work in electronic car market",
    "Apple's new iPhone failed to impress investors.",
    "The Fed raised interest rates by 0.25 points.",
]

# ë¼ë²¨ ì¶”ì¶œ
id2label = model.config.id2label  # ì˜ˆ: {0: 'Corporate/Industrial', 1: 'Equity Index', ...}

# ë¬¸ì¥ ë¶„ì„
for text in texts:
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = F.softmax(outputs.logits, dim=1)

    top_idx = probs.argmax().item()
    predicted_label = id2label[top_idx]
    confidence = probs[0][top_idx].item()

    print(f"\nğŸ“„ í…ìŠ¤íŠ¸: {text}")
    print(f"â†’ ì˜ˆì¸¡ ì£¼ì œ: {predicted_label} ({confidence * 100:.2f}%)")

    if confidence > 0.7:
        print("âœ… ê¸ˆìœµ ê´€ë ¨ ë¬¸ì¥ìœ¼ë¡œ ê°„ì£¼")
    else:
        print("âŒ ê¸ˆìœµ ê´€ë ¨ì„± ë‚®ìŒ")

"""ğŸ“„ í…ìŠ¤íŠ¸: hanseong makes amazing work in electronic car market

â†’ ì˜ˆì¸¡ ì£¼ì œ: Company | Product News (97.16%)

âœ… ê¸ˆìœµ ê´€ë ¨ ë¬¸ì¥ìœ¼ë¡œ ê°„ì£¼

ì´ëŸ° ê²°ê³¼ë¥¼ ë³´ë‹ˆ ê°€ì§œ ë‰´ìŠ¤ì— ëŒ€í•œ ëŒ€ì±…ë„ ë§ˆë ¨ í•„ìš”
"""

import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F

# ëª¨ë¸ ê²½ë¡œ
MODEL_NAME = "nickmuchi/finbert-tone-finetuned-finance-topic-classification"

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)

# CSV íŒŒì¼ ë¡œë“œ
df = pd.read_excel("/content/íŠ¸ìœ„í„°_ìˆ˜ì§‘_(Web)_20250507112834.xlsx")

# ë¼ë²¨ ì •ë³´
id2label = model.config.id2label

# ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
filtered_results = []

# content ì»¬ëŸ¼ì˜ ë¬¸ì¥ ë¶„ì„
for text in df["ë³¸ë¬¸"].astype(str):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = F.softmax(outputs.logits, dim=1)

    top_idx = probs.argmax().item()
    predicted_label = id2label[top_idx]
    confidence = probs[0][top_idx].item()

    if confidence > 0.7:
        filtered_results.append({
            "text": text,
            "predicted_topic": predicted_label,
            "confidence": round(confidence * 100, 2)
        })

# ê²°ê³¼ DataFrameìœ¼ë¡œ ë³€í™˜ ë° ì €ì¥
filtered_df = pd.DataFrame(filtered_results)
filtered_df
# filtered_df.to_excel("finance_related_texts.xlsx", index=False)

"""# Main code"""

import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification
import torch
import torch.nn.functional as F
import math

# 1. ê¸ˆìœµ ê´€ë ¨ ì£¼ì œ ë¶„ë¥˜ ëª¨ë¸ (nickmuchi)
TOPIC_MODEL = "nickmuchi/finbert-tone-finetuned-finance-topic-classification"
topic_tokenizer = AutoTokenizer.from_pretrained(TOPIC_MODEL)
topic_model = AutoModelForSequenceClassification.from_pretrained(TOPIC_MODEL)
topic_id2label = topic_model.config.id2label

# 2. ê°ì„± ë¶„ì„ ëª¨ë¸ (ProsusAI/finbert)
SENTIMENT_MODEL = "ProsusAI/finbert"
sentiment_tokenizer = BertTokenizer.from_pretrained(SENTIMENT_MODEL)
sentiment_model = BertForSequenceClassification.from_pretrained(SENTIMENT_MODEL)
sentiment_labels = ["positive", "negative", "neutral"]

# 3. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_excel("/content/Filtered_Tweets.csv")
#ë§Œì•½ì— í¬ë¡¤ë§ ë°ì´í„°ê°€ csvíŒŒì¼ì´ë©´ pd.read.csv()í˜•ì‹ìœ¼ë¡œ

# 4. ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
results = []

# 5. ë¬¸ì¥ë³„ ì²˜ë¦¬
for text in df["fullText"].astype(str):
    # Step 1: ê¸ˆìœµ ê´€ë ¨ ë¬¸ì¥ í•„í„°ë§
    inputs_topic = topic_tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs_topic = topic_model(**inputs_topic)
        probs_topic = F.softmax(outputs_topic.logits, dim=1)

    top_idx = probs_topic.argmax().item()
    predicted_topic = topic_id2label[top_idx]
    topic_confidence = probs_topic[0][top_idx].item()

    # ê¸ˆìœµ ê´€ë ¨ë„ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§
    if topic_confidence > 0.7:
        # Step 2: ê°ì„± ë¶„ì„
        inputs_sentiment = sentiment_tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
        with torch.no_grad():
            outputs_sentiment = sentiment_model(**inputs_sentiment)
            probs_sentiment = F.softmax(outputs_sentiment.logits, dim=1)

        pos_prob = probs_sentiment[0][sentiment_labels.index("positive")].item()
        neg_prob = probs_sentiment[0][sentiment_labels.index("negative")].item()
        sentiment_score = pos_prob - neg_prob
        predicted_sentiment = sentiment_labels[probs_sentiment.argmax().item()]
        sentiment_confidence = probs_sentiment.max().item()

        # ê²°ê³¼ ì €ì¥
        results.append({
            "text": text,
            "predicted_topic": predicted_topic,
            "topic_confidence": round(topic_confidence * 100, 2),
            "predicted_sentiment": predicted_sentiment,
            "sentiment_score": round(sentiment_score, 4),
            "sentiment_confidence": round(sentiment_confidence * 100, 2)
        })

# 6. ê²°ê³¼ DataFrame ë³€í™˜
filtered_df = pd.DataFrame(results)

# sigmoid ë³´ì •ì„ í†µí•œ ê°€ì¤‘ ê°ì„± ì ìˆ˜ ê³„ì‚°
def sigmoid_adjust(conf):
    return 1 / (1 + math.exp(-10 * (conf - 0.5)))  # conf: 0~1ë¡œ ì •ê·œí™”ëœ í™•ì‹ ë„

# ìƒˆë¡œìš´ ì»¬ëŸ¼ ì¶”ê°€
filtered_df["sentiment_confidence_normalized"] = filtered_df["sentiment_confidence"] / 100  # 0~1 ë²”ìœ„ë¡œ ë³€í™˜
filtered_df["weighted_sentiment_score"] = filtered_df.apply(
    lambda row: row["sentiment_score"] * sigmoid_adjust(row["sentiment_confidence_normalized"]),
    axis=1
)

# 8. ê²°ê³¼ í™•ì¸
filtered_df.head()
# 7. ì €ì¥ (í•„ìš” ì‹œ ì£¼ì„ í•´ì œ)
filtered_df.to_excel("finance_sentiment_palantir.xlsx", index=False)

"""# ë‚ ì§œ í¬í•¨ ê°ì„± ë¶„ì„
ëŒ€ì‹  íŠ¸ìœ—ì´ ë‹´ê²¨ìˆëŠ” indexì™€ ë‚ ì§œ indexì˜ í˜•ì‹ì„ ë§ì¶°ì¤˜ì•¼í•¨


"""

import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification
import torch
import torch.nn.functional as F
import math

# 1. ê¸ˆìœµ ê´€ë ¨ ì£¼ì œ ë¶„ë¥˜ ëª¨ë¸ (nickmuchi)
TOPIC_MODEL = "nickmuchi/finbert-tone-finetuned-finance-topic-classification"
topic_tokenizer = AutoTokenizer.from_pretrained(TOPIC_MODEL)
topic_model = AutoModelForSequenceClassification.from_pretrained(TOPIC_MODEL)
topic_id2label = topic_model.config.id2label

# 2. ê°ì„± ë¶„ì„ ëª¨ë¸ (ProsusAI/finbert)
SENTIMENT_MODEL = "ProsusAI/finbert"
sentiment_tokenizer = BertTokenizer.from_pretrained(SENTIMENT_MODEL)
sentiment_model = BertForSequenceClassification.from_pretrained(SENTIMENT_MODEL)
sentiment_labels = ["positive", "negative", "neutral"]

# 3. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("/content/Filtered_Tweets.csv")

# 4. ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
results = []

# 5. ë¬¸ì¥ë³„ ì²˜ë¦¬
for text, date in zip(df["fullText"].astype(str), df["createdAt"]): # íŠ¸ìœ—ì´ ë‹´ê²¨ìˆëŠ” í•­ëª©ìœ¼ë¡œ ë°”ê¾¸ê¸°
    # Step 1: ê¸ˆìœµ ê´€ë ¨ ë¬¸ì¥ í•„í„°ë§
    inputs_topic = topic_tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs_topic = topic_model(**inputs_topic)
        probs_topic = F.softmax(outputs_topic.logits, dim=1)

    top_idx = probs_topic.argmax().item()
    predicted_topic = topic_id2label[top_idx]
    topic_confidence = probs_topic[0][top_idx].item()

    if topic_confidence > 0.7:
        # Step 2: ê°ì„± ë¶„ì„
        inputs_sentiment = sentiment_tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
        with torch.no_grad():
            outputs_sentiment = sentiment_model(**inputs_sentiment)
            probs_sentiment = F.softmax(outputs_sentiment.logits, dim=1)

        pos_prob = probs_sentiment[0][sentiment_labels.index("positive")].item()
        neg_prob = probs_sentiment[0][sentiment_labels.index("negative")].item()
        sentiment_score = pos_prob - neg_prob
        predicted_sentiment = sentiment_labels[probs_sentiment.argmax().item()]
        sentiment_confidence = probs_sentiment.max().item()

        results.append({
            "date": date,
            "text": text,
            "predicted_topic": predicted_topic,
            "topic_confidence": round(topic_confidence * 100, 2),
            "predicted_sentiment": predicted_sentiment,
            "sentiment_score": round(sentiment_score, 4),
            "sentiment_confidence": round(sentiment_confidence * 100, 2)
        })

# 6. ê²°ê³¼ DataFrame ë³€í™˜
filtered_df = pd.DataFrame(results)

# 7. sigmoid ë³´ì •ëœ ê°ì • ì ìˆ˜ ì¶”ê°€
def sigmoid_adjust(conf):
    return 1 / (1 + math.exp(-10 * (conf - 0.5)))

filtered_df["sentiment_confidence_normalized"] = filtered_df["sentiment_confidence"] / 100
filtered_df["weighted_sentiment_score"] = filtered_df.apply(
    lambda row: row["sentiment_score"] * sigmoid_adjust(row["sentiment_confidence_normalized"]),
    axis=1
)

# 8. Dateë¥¼ ì¸ë±ìŠ¤ë¡œ ì§€ì •í•˜ì—¬ ì €ì¥
filtered_df.set_index("date", inplace=True)
filtered_df.to_excel("sentiment_cleandata.xlsx")

# 9. ë¯¸ë¦¬ë³´ê¸°
filtered_df.head()